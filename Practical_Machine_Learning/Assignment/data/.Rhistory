Q()
q()
xt1 <- xtable(round(modelRf$finalModel$conf, 0), caption = "Training Data Set")
print(xt1, type = "html", floating = TRUE, caption.placement = "bottom")
library(caret)                  # Classification and Regression Training
library(data.table)             # Extension of Data Frame
library(ggplot2)                # Plotting
library(xtable)                 # For generating tables knitr
library(knitr)                  # Markdown
library(gridExtra)              # Grid for graphics
library(plyr)                   # Tools for splitting, applying and combining data
library(gtools)                 # Various R Programming Tools
path.expand("~")
setwd("~/Data_Analysis/Coursera/Practical_Machine_Learning/Assignment_files")
file <- "test.dat"
# Get Temporary Directory
tmpdir <- tempdir()
# Unzip the file into the dir
setwd("~/Data_Analysis/Coursera/Practical_Machine_Learning/Assignment_files/data/")
# Unzip Training - Testing Sets
unzip("pml-training.zip", exdir = tmpdir)
unzip("pml-testing.zip", exdir = tmpdir)
# Get / Define path & name of the unzipped
training_name <- paste(tmpdir, "pml-training.csv", sep = "\\")
testing_name <- paste(tmpdir, "pml-testing.csv", sep = "\\")
# Read zipfiles and creates DT (data table)
plm_training <- read.csv(training_name, header = TRUE, sep =",")
plm_training <- read.csv(training_name, header = TRUE, sep =",",
na.strings = c("", "#DIV/0!","NA"))
plm_testing <- read.csv(testing_name, header = TRUE, sep =",",
na.strings = c("", "#DIV/0!","NA"))
cleaning.data <- function(data){
# Generating Tidy Data Sets
colNames <- colnames(data)
# [1]
# Create vector with the NOT required column
colNames <- (colNames[(grepl("X",colNames)
| grepl("user_name",colNames)
| grepl("raw_timestamp_part_1",colNames)
| grepl("raw_timestamp_part_2",colNames)
| grepl("cvtd_timestamp",colNames)
| grepl("new_window",colNames)
| grepl("num_window",colNames)
| grepl("total_accel",colNames)
| grepl("kurtosis",colNames)
| grepl("skewness", colNames)
| grepl("max", colNames)
| grepl("min", colNames)
| grepl("amplitude", colNames)
| grepl("var", colNames)
| grepl("avg", colNames)
| grepl("stddev", colNames)
) == FALSE])
# [2]
# Create the Data Table with the required columns
data <- as.data.table(data)
data <- data[ , colNames, with = FALSE]
# Create "classe" vector
classe <- as.vector(data$classe)
# Create Data Frame with classe
data_classe <- data.frame(classe)
# Delete Column "classe"
colNames <- colnames(data)
colNames <- (colNames[(grepl("classe",colNames)) == FALSE])
data <- data[ , colNames, with = FALSE]
# Merge Data Frames
data <- cbind(data_classe, data)
}
path.expand("~")
setwd("~/Data_Analysis/Coursera/Practical_Machine_Learning/Assignment_files")
# Cleaning Data for "plm_training"" Data Set
tidy_dataset <- as.data.frame(cleaning.data(plm_training))
write.table(tidy_dataset, "./data/tidy_dataset.csv", row.names = FALSE , sep = ",")
# Cleaning Data for "plm_testing Data Set
# "classe" column do not exist for this dataset
colnames(plm_testing)[160] <- "classe"
validation_dataset <- cleaning.data(plm_testing)
# Return original Column Name
colnames(validation_dataset)[1] <- "problem_id"
write.table(validation_dataset, "./data/validation_dataset.csv", row.names = FALSE , sep = ",")
# NA Values
sum(is.na(tidy_dataset))
sum(is.na(validation_dataset))
path.expand("~")
setwd("~/Data_Analysis/Coursera/Practical_Machine_Learning/Assignment_files")
set.seed(12345)
inTrain <- createDataPartition(y = tidy_dataset$classe, p = 0.60, list = FALSE)
training <- tidy_dataset[inTrain, ]                	# 60%
testing <- tidy_dataset[-inTrain, ] 			# 40%
dim(training); dim(testing)
# Writing training and testing data sets
write.table(training, "./data/training.csv", row.names = FALSE , sep = ",")
write.table(testing, "./data/testing.csv", row.names = FALSE , sep = ",")
# Cleaning Enviroment
rm(list=setdiff(ls(), c("training", "testing", "validation_dataset")))
path.expand("~")
setwd("~/Data_Analysis/Coursera/Practical_Machine_Learning/Assignment_files/data")
# Specifiying Resampling Type
# Resampling Method: repeatedcv - http://topepo.github.io/caret/training.html
fitControl <- trainControl(## 5-fold CV
method = "repeatedcv",
number = 5,
## repeated 2 times
repeats = 2,
## Saving data into a slot called trainingData
returnData = TRUE,
## Estimate class probabilities
classProbs = TRUE,
## Allow Parallel Processing
allowParallel = TRUE
)
if (!file.exists("modelLvq.RData")){
system.time({
# LVQ Model - Learning Vector Quantization - Use: Classification
# Tunning Parameters: size, k
set.seed(12345)
modelLvq <- train(classe ~., data = training, method = "lvq",
preProcess = c("center", "scale"), trControl = fitControl)
})
save(modelLvq, file = "modelLvq.RData", compress = TRUE)
} else {
load(file = "modelLvq.RData")
}
if (!file.exists("modelGbm.RData")){
system.time({
# GBM Model - Stochastic Gradient Boosting - Dual Use
# Tunning Parameters: n.trees, interaction.depth, shrinkage
set.seed(12345)
modelGbm <- train(classe ~., data = training, method = "gbm",
preProcess = c("center", "scale"), trControl = fitControl)
})
save(modelGbm, file = "modelGbm.RData", compress = TRUE);
} else {
load(file = "modelGbm.RData")
}
if (!file.exists("modelSmv.RData")){
system.time({
# SVM Model - Support Vector Machines - Dual Use
# Tunning Parameters: sigma, C
set.seed(12345)
modelSmv <- train(classe ~., data = training, method = "svmRadial",
preProcess = c("center", "scale"), trControl = fitControl)
})
save(modelSmv, file = "modelSmv.RData", compress = TRUE)
} else {
load(file = "modelSmv.RData")
}
if (!file.exists("modelRf.RData")){
system.time({
# RF Model - Random Forest - Dual Use
# Tunning Parameters: mtry
set.seed(12345)
modelRf <- train(classe ~ ., data = training, method = "rf",
preProcess = c("center", "scale"), trControl = fitControl)
})
save(modelRf, file = "modelRf.RData", compress = TRUE);
} else {
load(file = "modelRf.RData")
}
# Collect Resamples
results <-resamples(list(LVQ = modelLvq, GBM = modelGbm, SVM = modelSmv,
RF = modelRf))
setwd("~/Data_Analysis/Coursera/Practical_Machine_Learning/Assignment_files/reports/")
answers <- read.csv(answers, header = TRUE, sep =",")
answers <- read.csv(answers.csv, header = TRUE, sep =",")
setwd("~/Data_Analysis/Coursera/Practical_Machine_Learning/Assignment_files/reports/")
answers <- read.csv(answers.csv, header = TRUE, sep =",")
answers <- read.csv(answers, header = TRUE, sep =",")
problem_id <- c(1:20)
answers <- c("B", "A", "B", "A", "A", "E", "D", "B", "A", "A",
"B", "C", "B", "A", "E", "E", "A", "B", "B", "B")
length(answers)
df <- rbind(problem_id, answers)
df
colNames <- colnames(validation_dataset)
t_test <- t.test(classe ~ , paired = FALSE, var.equal = TRUE, conf.level = 0.95,
data = testing)
library(caret)                  # Classification and Regression Training
library(data.table)             # Extension of Data Frame
library(ggplot2)                # Plotting
library(xtable)                 # For generating tables knitr
library(knitr)                  # Markdown
library(gridExtra)              # Grid for graphics
library(plyr)                   # Tools for splitting, applying and combining data
library(gtools)                 # Various R Programming Tools
file <- "test.dat"
# Get Temporary Directory
tmpdir <- tempdir()
# Unzip the file into the dir
setwd("~/Data_Analysis/Coursera/Practical_Machine_Learning/Assignment_files/data/")
# Unzip Training - Testing Sets
unzip("pml-training.zip", exdir = tmpdir)
unzip("pml-testing.zip", exdir = tmpdir)
# Get / Define path & name of the unzipped
training_name <- paste(tmpdir, "pml-training.csv", sep = "\\")
testing_name <- paste(tmpdir, "pml-testing.csv", sep = "\\")
# Read zipfiles and creates DT (data table)
plm_training <- read.csv(training_name, header = TRUE, sep =",")
plm_training <- read.csv(training_name, header = TRUE, sep =",",
na.strings = c("", "#DIV/0!","NA"))
plm_testing <- read.csv(testing_name, header = TRUE, sep =",",
na.strings = c("", "#DIV/0!","NA"))
cleaning.data <- function(data){
# Generating Tidy Data Sets
colNames <- colnames(data)
# [1]
# Create vector with the NOT required column
colNames <- (colNames[(grepl("X",colNames)
| grepl("user_name",colNames)
| grepl("raw_timestamp_part_1",colNames)
| grepl("raw_timestamp_part_2",colNames)
| grepl("cvtd_timestamp",colNames)
| grepl("new_window",colNames)
| grepl("num_window",colNames)
| grepl("total_accel",colNames)
| grepl("kurtosis",colNames)
| grepl("skewness", colNames)
| grepl("max", colNames)
| grepl("min", colNames)
| grepl("amplitude", colNames)
| grepl("var", colNames)
| grepl("avg", colNames)
| grepl("stddev", colNames)
) == FALSE])
# [2]
# Create the Data Table with the required columns
data <- as.data.table(data)
data <- data[ , colNames, with = FALSE]
# Create "classe" vector
classe <- as.vector(data$classe)
# Create Data Frame with classe
data_classe <- data.frame(classe)
# Delete Column "classe"
colNames <- colnames(data)
colNames <- (colNames[(grepl("classe",colNames)) == FALSE])
data <- data[ , colNames, with = FALSE]
# Merge Data Frames
data <- cbind(data_classe, data)
}
# Set the working directory
path.expand("~")
setwd("~/Data_Analysis/Coursera/Practical_Machine_Learning/Assignment_files")
# Cleaning Data for "plm_training"" Data Set
tidy_dataset <- as.data.frame(cleaning.data(plm_training))
write.table(tidy_dataset, "./data/tidy_dataset.csv", row.names = FALSE , sep = ",")
# Cleaning Data for "plm_testing Data Set
# "classe" column do not exist for this dataset
colnames(plm_testing)[160] <- "classe"
validation_dataset <- cleaning.data(plm_testing)
# Return original Column Name
colnames(validation_dataset)[1] <- "problem_id"
write.table(validation_dataset, "./data/validation_dataset.csv", row.names = FALSE , sep = ",")
# NA Values
sum(is.na(tidy_dataset))
sum(is.na(validation_dataset))
path.expand("~")
setwd("~/Data_Analysis/Coursera/Practical_Machine_Learning/Assignment_files")
set.seed(12345)
inTrain <- createDataPartition(y = tidy_dataset$classe, p = 0.60, list = FALSE)
training <- tidy_dataset[inTrain, ]                	# 60%
testing <- tidy_dataset[-inTrain, ] 			# 40%
dim(training); dim(testing)
# Writing training and testing data sets
write.table(training, "./data/training.csv", row.names = FALSE , sep = ",")
write.table(testing, "./data/testing.csv", row.names = FALSE , sep = ",")
# Cleaning Enviroment
rm(list=setdiff(ls(), c("training", "testing", "validation_dataset")))
path.expand("~")
setwd("~/Data_Analysis/Coursera/Practical_Machine_Learning/Assignment_files/data")
# Specifiying Resampling Type
# Resampling Method: repeatedcv - http://topepo.github.io/caret/training.html
fitControl <- trainControl(## 5-fold CV
method = "repeatedcv",
number = 5,
## repeated 2 times
repeats = 2,
## Saving data into a slot called trainingData
returnData = TRUE,
## Estimate class probabilities
classProbs = TRUE,
## Allow Parallel Processing
allowParallel = TRUE
)
if (!file.exists("modelLvq.RData")){
system.time({
# LVQ Model - Learning Vector Quantization - Use: Classification
# Tunning Parameters: size, k
set.seed(12345)
modelLvq <- train(classe ~., data = training, method = "lvq",
preProcess = c("center", "scale"), trControl = fitControl)
})
save(modelLvq, file = "modelLvq.RData", compress = TRUE)
} else {
load(file = "modelLvq.RData")
}
if (!file.exists("modelGbm.RData")){
system.time({
# GBM Model - Stochastic Gradient Boosting - Dual Use
# Tunning Parameters: n.trees, interaction.depth, shrinkage
set.seed(12345)
modelGbm <- train(classe ~., data = training, method = "gbm",
preProcess = c("center", "scale"), trControl = fitControl)
})
save(modelGbm, file = "modelGbm.RData", compress = TRUE);
} else {
load(file = "modelGbm.RData")
}
if (!file.exists("modelSmv.RData")){
system.time({
# SVM Model - Support Vector Machines - Dual Use
# Tunning Parameters: sigma, C
set.seed(12345)
modelSmv <- train(classe ~., data = training, method = "svmRadial",
preProcess = c("center", "scale"), trControl = fitControl)
})
save(modelSmv, file = "modelSmv.RData", compress = TRUE)
} else {
load(file = "modelSmv.RData")
}
if (!file.exists("modelRf.RData")){
system.time({
# RF Model - Random Forest - Dual Use
# Tunning Parameters: mtry
set.seed(12345)
modelRf <- train(classe ~ ., data = training, method = "rf",
preProcess = c("center", "scale"), trControl = fitControl)
})
save(modelRf, file = "modelRf.RData", compress = TRUE);
} else {
load(file = "modelRf.RData")
}
# Collect Resamples
results <-resamples(list(LVQ = modelLvq, GBM = modelGbm, SVM = modelSmv,
RF = modelRf))
predictions <- predict(modelRf, newdata = testing)
# Confusion Matrix Testing
cm <- confusionMatrix(predictions, testing$classe)
str(cm)
# In Sample Error - Training / Testing Data Sets from selected model
# Values extracted from Training Data Set
bestmodel <- "Random Forest - Classification"
maxaccuracy <- max(modelRf$results[, "Accuracy"])
maxkappa <- max(modelRf$results[, "Kappa"])
minmtry <- min(modelRf$results[, "mtry"])
# OOB_Training Calculation:
OK <- sum(modelRf$finalModel$conf[1, 1],
modelRf$finalModel$conf[2, 2],
modelRf$finalModel$conf[3, 3],
modelRf$finalModel$conf[4, 4],
modelRf$finalModel$conf[5, 5])
NOK <- nrow(training) - OK
OOB_Training <- (NOK/nrow(training)) * 100
# Out Sample Error - Testing Data Set
cmoverall <- cm$overall
# OOB_Testing Calculation:
OK <- sum(cm$table[1, 1],
cm$table[2, 2],
cm$table[3, 3],
cm$table[4, 4],
cm$table[5, 5])
NOK <- nrow(testing) - OK
OOB_Testing <- (NOK/nrow(testing)) * 100
accuracy <- cmoverall["Accuracy"]
kappa  <- cmoverall["Kappa"]
confInterval <- c(cmoverall["AccuracyLower"], cmoverall["AccuracyUpper"])
pvalue <- format(cmoverall["AccuracyPValue"], scientific=TRUE)
# Error Confusion Matrix Testing Data Set
confusionMatrixTable <- as.data.table(cm$table)
# Sensitivity - Specificity Testing Data SeT
classA <- c(cm$byClass[1, 1], cm$byClass[1, 2])
classB <- c(cm$byClass[2, 1], cm$byClass[2, 2])
classC <- c(cm$byClass[3, 1], cm$byClass[3, 2])
classD <- c(cm$byClass[4, 1], cm$byClass[4, 2])
classE <- c(cm$byClass[5, 1], cm$byClass[4, 2])
t_test <- t.test(classe ~ , paired = FALSE, var.equal = TRUE, conf.level = 0.95,
data = testing)
predictions <- predict(modelRf, newdata = testing)
t_test <- t.test(classe ~ , paired = FALSE, var.equal = TRUE, conf.level = 0.95,
data = predictions)
t_test <- t.test(classe ~ , paired = FALSE, var.equal = TRUE, conf.level = 0.95, data = predictions)
predictions
t_test <- t.test(classe ~ , paired = FALSE, var.equal = TRUE, conf.level = 0.95, data = testing)
View(testing)
predictions <- predict(modelRf, newdata = testing)
subdata <- predictions[predictions %in% c("A", "B", "C", "D", "E"), ]
group <- as.character(predcitions)
group <- as.character(predictions)
data(sleep)
sleep
x <- predict(modelRf, newdata = testing)
test(x, y = NULL, alternative = c("two.sided", "less", "greater"), mu = 0, paired = FALSE, var.equal = FALSE, conf.level = 0.95)
t-test(x, y = NULL, alternative = c("two.sided", "less", "greater"), mu = 0, paired = FALSE, var.equal = FALSE, conf.level = 0.95)
t.test(x, y = NULL, alternative = c("two.sided", "less", "greater"), mu = 0, paired = FALSE, var.equal = FALSE, conf.level = 0.95)
