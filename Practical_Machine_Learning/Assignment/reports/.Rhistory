Q()
q()
library(caret)                  # Classification and Regression Training
library(data.table)             # Extension of Data Frame
library(ggplot2)                # Plotting
library(xtable)                 # For generating tables knitr
library(knitr)                  # Markdown
library(gridExtra)              # Grid for graphics
library(plyr)                   # Tools for splitting, applying and combining data
library(gtools)                 # Various R Programming Tools
path.expand("~")
setwd("~/Data_Analysis/Coursera/Practical_Machine_Learning/Assignment_files")
file <- "test.dat"
# Get Temporary Directory
tmpdir <- tempdir()
# Unzip the file into the dir
setwd("~/Data_Analysis/Coursera/Practical_Machine_Learning/Assignment_files/data/")
# Unzip Training - Testing Sets
unzip("pml-training.zip", exdir = tmpdir)
unzip("pml-testing.zip", exdir = tmpdir)
# Get / Define path & name of the unzipped
training_name <- paste(tmpdir, "pml-training.csv", sep = "\\")
testing_name <- paste(tmpdir, "pml-testing.csv", sep = "\\")
# Read zipfiles and creates DT (data table)
plm_training <- read.csv(training_name, header = TRUE, sep =",")
plm_training <- read.csv(training_name, header = TRUE, sep =",",
na.strings = c("", "#DIV/0!","NA"))
plm_testing <- read.csv(testing_name, header = TRUE, sep =",",
na.strings = c("", "#DIV/0!","NA"))
cleaning.data <- function(data){
# Generating Tidy Data Sets
colNames <- colnames(data)
# [1]
# Create vector with the NOT required column
colNames <- (colNames[(grepl("X",colNames)
| grepl("user_name",colNames)
| grepl("raw_timestamp_part_1",colNames)
| grepl("raw_timestamp_part_2",colNames)
| grepl("cvtd_timestamp",colNames)
| grepl("new_window",colNames)
| grepl("num_window",colNames)
| grepl("total_accel",colNames)
| grepl("kurtosis",colNames)
| grepl("skewness", colNames)
| grepl("max", colNames)
| grepl("min", colNames)
| grepl("amplitude", colNames)
| grepl("var", colNames)
| grepl("avg", colNames)
| grepl("stddev", colNames)
) == FALSE])
# [2]
# Create the Data Table with the required columns
data <- as.data.table(data)
data <- data[ , colNames, with = FALSE]
# Create "classe" vector
classe <- as.vector(data$classe)
# Create Data Frame with classe
data_classe <- data.frame(classe)
# Delete Column "classe"
colNames <- colnames(data)
colNames <- (colNames[(grepl("classe",colNames)) == FALSE])
data <- data[ , colNames, with = FALSE]
# Merge Data Frames
data <- cbind(data_classe, data)
}
tidy_dataset <- as.data.frame(cleaning.data(plm_training))
write.table(tidy_dataset, "./data/tidy_dataset.csv", row.names = FALSE , sep = ",")
# Cleaning Data for "plm_testing Data Set
# "classe" column do not exist for this dataset
colnames(plm_testing)[160] <- "classe"
validation_dataset <- cleaning.data(plm_testing)
# Return original Column Name
colnames(validation_dataset)[1] <- "problem_id"
write.table(validation_dataset, "./data/validation_dataset.csv", row.names = FALSE , sep = ",")
# NA Values
sum(is.na(tidy_dataset))
sum(is.na(validation_dataset))
path.expand("~")
setwd("~/Data_Analysis/Coursera/Practical_Machine_Learning/Assignment_files")
path.expand("~")
setwd("~/Data_Analysis/Coursera/Practical_Machine_Learning/Assignment_files")
# Cleaning Data for "plm_training"" Data Set
tidy_dataset <- as.data.frame(cleaning.data(plm_training))
write.table(tidy_dataset, "./data/tidy_dataset.csv", row.names = FALSE , sep = ",")
# Cleaning Data for "plm_testing Data Set
# "classe" column do not exist for this dataset
colnames(plm_testing)[160] <- "classe"
validation_dataset <- cleaning.data(plm_testing)
# Return original Column Name
colnames(validation_dataset)[1] <- "problem_id"
write.table(validation_dataset, "./data/validation_dataset.csv", row.names = FALSE , sep = ",")
# NA Values
sum(is.na(tidy_dataset))
sum(is.na(validation_dataset))
path.expand("~")
setwd("~/Data_Analysis/Coursera/Practical_Machine_Learning/Assignment_files")
set.seed(12345)
inTrain <- createDataPartition(y = tidy_dataset$classe, p = 0.60, list = FALSE)
training <- tidy_dataset[inTrain, ]                	# 60%
testing <- tidy_dataset[-inTrain, ] 			# 40%
dim(training); dim(testing)
# Writing training and testing data sets
write.table(training, "./data/training.csv", row.names = FALSE , sep = ",")
write.table(testing, "./data/testing.csv", row.names = FALSE , sep = ",")
# Cleaning Enviroment
rm(list=setdiff(ls(), c("training", "testing", "validation_dataset")))
path.expand("~")
setwd("~/Data_Analysis/Coursera/Practical_Machine_Learning/Assignment_files/data")
# Specifiying Resampling Type
# Resampling Method: repeatedcv - http://topepo.github.io/caret/training.html
fitControl <- trainControl(## 5-fold CV
method = "repeatedcv",
number = 5,
## repeated 2 times
repeats = 2,
## Saving data into a slot called trainingData
returnData = TRUE,
## Estimate class probabilities
classProbs = TRUE,
## Allow Parallel Processing
allowParallel = TRUE
)
if (!file.exists("modelLvq.RData")){
system.time({
# LVQ Model - Learning Vector Quantization - Use: Classification
# Tunning Parameters: size, k
set.seed(12345)
modelLvq <- train(classe ~., data = training, method = "lvq",
preProcess = c("center", "scale"), trControl = fitControl)
})
save(modelLvq, file = "modelLvq.RData", compress = TRUE)
} else {
load(file = "modelLvq.RData")
}
if (!file.exists("modelGbm.RData")){
system.time({
# GBM Model - Stochastic Gradient Boosting - Dual Use
# Tunning Parameters: n.trees, interaction.depth, shrinkage
set.seed(12345)
modelGbm <- train(classe ~., data = training, method = "gbm",
preProcess = c("center", "scale"), trControl = fitControl)
})
save(modelGbm, file = "modelGbm.RData", compress = TRUE);
} else {
load(file = "modelGbm.RData")
}
if (!file.exists("modelSmv.RData")){
system.time({
# SVM Model - Support Vector Machines - Dual Use
# Tunning Parameters: sigma, C
set.seed(12345)
modelSmv <- train(classe ~., data = training, method = "svmRadial",
preProcess = c("center", "scale"), trControl = fitControl)
})
save(modelSmv, file = "modelSmv.RData", compress = TRUE)
} else {
load(file = "modelSmv.RData")
}
if (!file.exists("modelRf.RData")){
system.time({
# RF Model - Random Forest - Dual Use
# Tunning Parameters: mtry
set.seed(12345)
modelRf <- train(classe ~ ., data = training, method = "rf",
preProcess = c("center", "scale"), trControl = fitControl)
})
save(modelRf, file = "modelRf.RData", compress = TRUE);
} else {
load(file = "modelRf.RData")
}
# Collect Resamples
results <-resamples(list(LVQ = modelLvq, GBM = modelGbm, SVM = modelSmv,
RF = modelRf))
predictions <- predict(modelRf, newdata = testing)
# Confusion Matrix Testing
cm <- confusionMatrix(predictions, testing$classe)
cm
modelRf$finalModel$conf
modelRf$finalModel$conf[1]
modelRf$finalModel$conf[2]
modelRf$finalModel$conf[1] # A_Ok
modelRf$finalModel$conf[1, 1] # A_Ok
+ modelRf$finalModel$conf[2, 2] # B_Ok
+ modelRf$finalModel$conf[3, 3] # C_Ok
+ modelRf$finalModel$conf[4, 4] # D_Ok
+ modelRf$finalModel$conf[5, 5] # E_Ok
OK <- modelRf$finalModel$conf[1, 1] # A_Ok
+ modelRf$finalModel$conf[2, 2] # B_Ok
+ modelRf$finalModel$conf[3, 3] # C_Ok
+ modelRf$finalModel$conf[4, 4] # D_Ok
+ modelRf$finalModel$conf[5, 5] # E_Ok
OK <- sum(modelRf$finalModel$conf[1, 1] # A_Ok,
modelRf$finalModel$conf[2, 2] # B_Ok,
modelRf$finalModel$conf[3, 3] # C_Ok,
modelRf$finalModel$conf[4, 4] # D_Ok,
modelRf$finalModel$conf[5, 5] # E_Ok)
OK <- sum(modelRf$finalModel$conf[1, 1],
modelRf$finalModel$conf[2, 2],
modelRf$finalModel$conf[3, 3],
modelRf$finalModel$conf[4, 4],
modelRf$finalModel$conf[5, 5])
OK
sum(modelRf$finalModel$conf)
sum(modelRf$finalModel$conf[1:5])
modelRf$finalModel$conf
sum(modelRf$finalModel$conf[1, 6]
)
NOK <- sum(modelRf$finalModel$conf) -  sum(modelRf$finalModel$conf[1, 6]
NOK
NOK <- sum(modelRf$finalModel$conf) - sum(modelRf$finalModel$conf[1, 6]
NOK
NOK <- sum(modelRf$finalModel$conf) - sum(modelRf$finalModel$conf[1, 6])
NOK
modelRf$finalModel$conf
matrix <- as.matrix(modelRf$finalModel$conf)
matrix
matrix[1,1]
ncol(matrix)
nrow(matrix)
modelRf$finalModel$conf[2:5, 1]
sum(modelRf$finalModel$conf[2:5, 1])
nrow(training)
NOK <- nrow(training) - OK
NOK
OOB <- NOK/nrow(training)
?perecntage
?percentage
?%
OOB <- (NOK/nrow(training)) * 100%
?format
ls(matrix)
x <- data[i, 1]
x <- data[1, 1]
data <- answers
View(validation_dataset)
# Run Model for predicting Values
answers <- predict(modelRf, data)
answers <- as.data.frame(answers)
colnames(answers) <- c("predicted_classe")
# Problem Id
problemId <- data.frame(problem_id = c(1:20))
# Merge Data Frames with data & results
answerdata <- cbind(problemId, answers, data)
# Set Working Directory
path.expand("~")
setwd("~/Data_Analysis/Coursera/Practical_Machine_Learning/Assignment_files")
answerdata <- as.data.frame(answerdata)
write.table(answerdata, "./reports/answers.csv", row.names = FALSE , sep = ",")
# Generating Answer Data Set
colNames <- colnames(validation_dataset)
# [1]
# Create vector with the NOT required column
colNames <- (colNames[(grepl("problem_id",colNames)) == FALSE])
#[2]
# Create Data Table
data <- as.data.table(validation_dataset)
data <- data[ , colNames, with = FALSE]
# Run Model for predicting Values
answers <- predict(modelRf, data)
answers <- as.data.frame(answers)
colnames(answers) <- c("predicted_classe")
# Problem Id
problemId <- data.frame(problem_id = c(1:20))
# Merge Data Frames with data & results
answerdata <- cbind(problemId, answers, data)
# Set Working Directory
path.expand("~")
setwd("~/Data_Analysis/Coursera/Practical_Machine_Learning/Assignment_files")
answerdata <- as.data.frame(answerdata)
write.table(answerdata, "./reports/answers.csv", row.names = FALSE , sep = ",")
data <- answers
x <- data[1, 1]
x
# Execute Function
loopLength <- nrow(data)
for(i in 1:loopLength){
x <- data[i, 1]
answers <- rep(x, i)
filename = paste0("problem_id_",i,".txt")
write.table(x, file = filename, quote = FALSE, row.names = FALSE,
col.names = FALSE)
}
path.expand("~")
setwd("~/Data_Analysis/Coursera/Practical_Machine_Learning/Assignment_files/reports/")
# Execute Function
loopLength <- nrow(data)
for(i in 1:loopLength){
x <- data[i, 1]
answers <- rep(x, i)
filename = paste0("problem_id_",i,".txt")
write.table(x, file = filename, quote = FALSE, row.names = FALSE,
col.names = FALSE)
}
cm$table
cmoverall <- cm$overall
cmoverall
cm&table[1,1]
cm$table[1,1]
# OOB_Testing Calculation:
OK <- sum(cm$table[1, 1],
cm$table[2, 2],
cm$table[3, 3],
cm$table[4, 4],
cm$table[5, 5])
NOK <- nrow(testing) - OK
OOB_Testing <- (NOK/nrow(testing)) * 100
OOB_Testing
q()
